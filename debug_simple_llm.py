#!/usr/bin/env python3
"""
Debug with a simple LLM call to see if the issue is with the prompt or the LLM.
"""

import asyncio
import sys
import os

# Add the backend to the path
sys.path.insert(0, '/Users/Mariam/word-addin-mcp/backend')

from app.services.patent_search_service import PatentSearchService

async def debug_simple_llm():
    """Debug with a simple LLM call."""
    print("ğŸ” Debugging Simple LLM Call...")
    
    try:
        # Create the service instance
        service = PatentSearchService()
        print("âœ… Service created")
        
        # Test with a very simple prompt
        print("ğŸ” Testing simple prompt...")
        simple_prompt = "Write a short paragraph about 5G technology."
        
        response = service.llm_client.generate_text(
            prompt=simple_prompt,
            max_tokens=100
        )
        
        print(f"âœ… Simple LLM response received")
        print(f"ğŸ“Š Response type: {type(response)}")
        print(f"ğŸ“Š Success: {response.get('success', False)}")
        print(f"ğŸ“ Text length: {len(response.get('text', ''))}")
        
        if response.get('text'):
            print(f"ğŸ“„ Text: {response['text']}")
        else:
            print("âŒ No text in simple response")
            print(f"ğŸ“Š Full response: {response}")
        
        # Test with a slightly more complex prompt
        print("\nğŸ” Testing medium prompt...")
        medium_prompt = """Generate a brief prior art search report for 5G AI technology.

Include:
1. Executive Summary
2. Key findings
3. Recommendations

Keep it concise but informative."""

        response2 = service.llm_client.generate_text(
            prompt=medium_prompt,
            max_tokens=500
        )
        
        print(f"âœ… Medium LLM response received")
        print(f"ğŸ“Š Response type: {type(response2)}")
        print(f"ğŸ“Š Success: {response2.get('success', False)}")
        print(f"ğŸ“ Text length: {len(response2.get('text', ''))}")
        
        if response2.get('text'):
            print(f"ğŸ“„ Text preview: {response2['text'][:300]}...")
        else:
            print("âŒ No text in medium response")
            print(f"ğŸ“Š Full response: {response2}")
            
    except Exception as e:
        print(f"âŒ Error during debug: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(debug_simple_llm())
