#!/usr/bin/env python3
"""
Debug the actual model configuration being used
"""

import sys
import os

# Add the backend to the path
sys.path.insert(0, '/Users/Mariam/word-addin-mcp/backend')

from app.core.config import settings
from app.services.llm_client import LLMClient

def debug_model_config():
    """Debug the model configuration."""
    print("ğŸ” Debugging Model Configuration")
    print("=" * 50)
    
    print(f"ğŸ“Š Azure OpenAI API Key: {'âœ… Set' if settings.azure_openai_api_key else 'âŒ Not set'}")
    print(f"ğŸ“Š Azure OpenAI Endpoint: {settings.azure_openai_endpoint}")
    print(f"ğŸ“Š Azure OpenAI Deployment: {settings.azure_openai_deployment}")
    print(f"ğŸ“Š Azure OpenAI API Version: {settings.azure_openai_api_version}")
    
    # Create LLM client
    try:
        llm_client = LLMClient(
            azure_openai_api_key=settings.azure_openai_api_key,
            azure_openai_endpoint=settings.azure_openai_endpoint,
            azure_openai_deployment=settings.azure_openai_deployment
        )
        
        print(f"\nğŸ“Š LLM Client Model: {llm_client.azure_openai_deployment}")
        print(f"ğŸ“Š LLM Client Available: {llm_client.llm_available}")
        print(f"ğŸ“Š LLM Client Endpoint: {llm_client.azure_openai_endpoint}")
        
        # Test a simple LLM call
        print(f"\nğŸ” Testing simple LLM call...")
        response = llm_client.generate_text("Hello, how are you?", max_tokens=50)
        
        print(f"ğŸ“Š LLM Response Success: {response.get('success', False)}")
        print(f"ğŸ“Š LLM Response Text Length: {len(response.get('text', ''))}")
        print(f"ğŸ“Š LLM Response Model: {response.get('model', 'N/A')}")
        
        if response.get('text'):
            print(f"ğŸ“„ LLM Response: {response['text']}")
            print("âœ… LLM is generating text!")
        else:
            print("âŒ LLM is not generating text")
            print(f"ğŸ“„ Full Response: {response}")
            
    except Exception as e:
        print(f"âŒ Error creating LLM client: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_model_config()
